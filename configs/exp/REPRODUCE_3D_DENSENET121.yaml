# @package _global_

defaults:
  - 3d_base_heatmap
  - override /model/encoder: 3d_smp
  - _self_

task:
  _target_: src.byu.task.heatmap_3d_task.Heatmap3dTask
  metrics:
    train/loss_epoch: min
    val/loss: min
    val/PAP: max
    val/mPAP: max
    val/Fbeta: max
    val/Precision: val/Fbeta
    val/Recall: val/Fbeta
    val/thres: val/Fbeta
    val/bestR: max
    val/AP: max
    val/mAP: max
    val/kaggleFbeta: max
  metric_keep_top_k: 1
  metric: val/Fbeta
  metric_mode: ${task.metrics.${task.metric}}
  log_metrics:
  - val/PAP
  - val/mPAP
  - val/Fbeta
  - val/Precision
  - val/Recall
  - val/thres
  - val/bestR
  - val/AP
  - val/mAP
  - val/loss
  - train/loss_epoch
  - val/loss
  decode:
    heatmap_stride:
    - 16
    - 16
    - 16
    method: nms
    act: sigmoid
    conf_thres: 0.01
    max_dets: 1
    timeout: 3
    nms:
      pool_ksize: null
      radius_thres: null
data:
  _target_: yagm.data.base_data_module.BaseDataModule
  _dataset_target_: byu.data.datasets.heatmap_3d_dataset.Heatmap3dDataset
  label_fname: all_gt_v3
  patch_size:
  - 224
  - 448
  - 448
  start:
  - 0
  - 0
  - 0
  overlap:
  - 0
  - 0
  - 0
  border:
  - 0
  - 0
  - 0
  sigma: 0.2
  fast_val_workers: 8
  fast_val_prefetch: 5
  io_backend: cv2
  crop_outside: true
  ensure_fg: false
  label_smooth:
  - 0.0
  - 1.0
  filter_rule: null
  sampling:
    method: pre_patch
    pre_patch:
      fg_max_dup: 1
      bg_ratio: 0.05
      bg_from_pos_ratio: 0.25
      overlap:
      - 0
      - 0
      - 0
    rand_crop:
      random_center: true
      margin: 0.25
      auto_correct_center: true
      pos_weight: 1
      neg_weight: 1
  transform:
    resample_mode: trilinear
    target_spacing:
    - 16
    - 16
    - 16
    heatmap_mode: gaussian
    heatmap_stride:
    - 16
    - 16
    - 16
    heatmap_same_sigma: false
    heatmap_same_std: true
    lazy: true
    device: null
  aug:
    enable: true
    zoom_prob: 0.4
    zoom_range:
    - - 0.6
      - 1.2
    - - 0.6
      - 1.2
    - - 0.6
      - 1.2
    affine1_prob: 0.5
    affine1_scale: 0.3
    affine2_prob: 0.25
    affine2_rotate_xy: 15
    affine2_scale: 0.3
    affine2_shear: 0.2
    rand_shift: false
    grid_distort_prob: 0.0
    smooth_deform_prob: 0.0
    intensity_prob: 0.5
    smooth_prob: 0.0
    hist_equalize: false
    downsample_prob: 0.2
    coarse_dropout_prob: 0.1
    mixup_prob: 0.0
    cutmix_prob: 0.0
    mixer_alpha: 1.0
    mixup_target_mode: max
  tta:
    enable:
    - zyx
    - zxy
    - zyx_x
    - zyx_y
model:
  encoder:
    _target_: byu.models.encoders.smp.SMPEncoder
    model_name: densenet121
    weights: imagenet
  _target_: byu.models.unet_3d.Unet3dModel
  decoder:
    decoder_channels:
    - 192
    - 96
    - 48
    n_blocks: 1
    use_batchnorm: true
    attention_type: scse
    center: false
    strides:
    - - 2
      - 2
      - 2
    - - 2
      - 2
      - 2
    - - 2
      - 2
      - 2
    - - 2
      - 2
      - 2
    - - 2
      - 2
      - 2
    weight_init: xavier
  head:
    ms:
    - 0
    out_channels: 1
    weight_init: xavier
  neck:
    _target_: yagm.layers.neck.FactorizedFPN3d
    intermediate_channels_list: 32
    target_level: -2
    conv_ksizes:
    - 3
    - 3
    norm: layernorm_3d
    act: gelu
    interpolation_mode: trilinear
loss:
  _target_: byu.loss.loss.CombineLoss
  losses:
  - bce:
      _target_: byu.loss.loss.BCEWithLogitsLoss
      reduction: mean
      pos_weight: null
  - tversky:
      _target_: byu.loss.monai_tversky.TverskyLoss
      include_background: true
      to_onehot_y: false
      sigmoid: true
      softmax: false
      other_act: null
      alpha: 0.2
      beta: 0.8
      reduction: mean
      smooth_nr: 0.01
      smooth_dr: 0.01
      batch: true
      soft_label: true
  pre_scale:
    bce: 1.0
    tversky: 0.001
  combine_mtl:
    method: scalar
    weights:
    - 1.0
    - 0.0
loader:
  steps_per_epoch: -1
  train_batch_size: 2
  val_batch_size: 1
  num_workers: 8
  pytorch_num_threads: 8
  pin_memory: false
  drop_last: true
  persistent_workers: false
  batch_sampler: null
  train_num_workers: 32
  val_num_workers: 8
callbacks:
  model_checkpoint:
    _target_: yagm.utils.lightning.CustomModelCheckpoint
    metrics: null
    dirpath: ${env.output_dir}/fold_${cv.fold_idx}/ckpts
    verbose: true
    save_last: link
    save_top_k: -1
    auto_insert_metric_name: false
    save_weights_only: false
    every_n_train_steps: 2000
    train_time_interval: null
    every_n_epochs: null
    save_on_train_epoch_end: false
    enable_version_counter: false
  early_stopping:
    _target_: lightning.pytorch.callbacks.EarlyStopping
    monitor: ${task.metric}
    min_delta: 0.0
    patience: 4
    verbose: true
    mode: ${task.metric_mode}
    strict: true
    check_finite: true
    stopping_threshold: null
    divergence_threshold: null
    check_on_train_epoch_end: false
    log_rank_zero_only: true
  lr_monitor:
    _target_: lightning.pytorch.callbacks.LearningRateMonitor
    logging_interval: null
    log_momentum: false
    log_weight_decay: false
  model_summary:
    _target_: lightning.pytorch.callbacks.ModelSummary
    max_depth: 4
  tqdm_progress_bar:
    _target_: yagm.utils.lightning.CustomTQDMProgressBar
    refresh_rate: 1
    process_position: 0
  validation_scheduler:
    _target_: yagm.utils.lightning.ValidationScheduler
    milestones:
    - 100000
    val_check_intervals:
    - 2000
    check_val_every_n_epochs: null
    milestone_unit: step
loggers:
  csv:
    _target_: lightning.pytorch.loggers.csv_logs.CSVLogger
    save_dir: ${env.output_dir}/fold_${cv.fold_idx}/
    name: csv_logs
    version: ''
    prefix: ''
    flush_logs_every_n_steps: 100
  wandb:
    _target_: lightning.pytorch.loggers.wandb.WandbLogger
    name: ${_or:${exp_name}_fold${cv.fold_idx}, ${now:%m-%d}|${now:%H-%M-%S}_${_no_slash:${hydra:job.override_dirname}}}
    save_dir: ${env.output_dir}/fold_${cv.fold_idx}/
    version: ''
    offline: false
    id: null
    anonymous: null
    project: byu
    log_model: false
    experiment: null
    prefix: ''
    checkpoint_name: null
    group: ''
    tags: ${all_tags}
    job_type: ''
trainer:
  accelerator: gpu
  strategy: auto
  devices: auto
  num_nodes: 1
  precision: 16-mixed
  fast_dev_run: 0
  max_epochs: null
  min_epochs: null
  max_steps: 32000
  min_steps: null
  max_time: null
  limit_train_batches: null
  limit_val_batches: null
  limit_test_batches: null
  limit_predict_batches: null
  overfit_batches: 0.0
  val_check_interval: 32000
  check_val_every_n_epoch: null
  num_sanity_val_steps: 0
  log_every_n_steps: 5
  enable_checkpointing: true
  enable_progress_bar: true
  enable_model_summary: true
  accumulate_grad_batches: 2
  gradient_clip_val: null
  gradient_clip_algorithm: null
  cudnn: true
  deterministic: false
  benchmark: false
  inference_mode: true
  use_distributed_sampler: true
  profiler: null
  detect_anomaly: false
  barebones: false
  plugins: null
  sync_batchnorm: false
  dist_batchnorm: ''
  reload_dataloaders_every_n_epochs: 0
  default_root_dir: ${env.output_dir}
  torch_compile:
    enable: false
    fullgraph: false
    dynamic: null
    mode: null
optim:
  name: torch@adamw
  lr: 0.0005
  weight_decay: 0.0
  betas:
  - 0.9
  - 0.999
  eps: 1.0e-07
scheduler:
  name: timm@cosine
  max_epochs: ${trainer.max_epochs}
  max_steps: ${trainer.max_steps}
  steps_per_epoch: ${loader.steps_per_epoch}
  warmup_steps: 3000
  warmup_epochs: null
  cooldown_epochs: 0
  lr: ${optim.lr}
  min_lr_factor: 0.005
  warmup_lr_factor: 0.01
  cycle_limit: 1
  cycle_decay: 0.5
  metric: ${task.metric}
  metric_mode: ${task.metric_mode}
env:
  data_dir: data
  output_dir: ${hydra:runtime.output_dir}
  fold_output_dir: ${env.output_dir}/fold_${cv.fold_idx}/
  output_metadata_dir: ${env.output_dir}/fold_${cv.fold_idx}/metadata/
  output_viz_dir: ${env.output_dir}/fold_${cv.fold_idx}/viz/
  cwd_dir: ${hydra:runtime.cwd}
cv:
  strategy: skf4_rd42
  num_folds: 4
  fold_idx: 0
  train_on_all: true
ema:
  enable: true
  train_decays:
  - 0.99
  val_decays:
  - 0.99
  test_decays: ${ema.train_decays}
  force_cpu: false
  reset_from: global_best
  reset_sched_epochs:
  - -1
  reset_on_plateau: -1
  min_reset_interval: 5
misc:
  log_level: INFO
  log_raw_cfg: false
  log_cfg: true
  log_cfg_rich: true
  log_model: true
  cooldown_sec: 0.0
ckpt:
  path: null
  name: best.ckpt
  strict: true
tags:
- heatmap
- unet
- smp
all_tags: ${tags}
train: true
val: false
test: false
predict: false
oof_eval: true
seed: 2210
exp_name: UNET3D_DENSENET121-ALLGTV3-SEED2210-LR5e-4