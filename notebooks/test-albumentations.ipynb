{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d917029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import PIL\n",
    "from IPython.display import Image\n",
    "from IPython.display import display as idisplay\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import albumentations as A\n",
    "import importlib\n",
    "from yagm.transforms import albumentations_custom as AC\n",
    "import polars as pl\n",
    "importlib.reload(AC)\n",
    "\n",
    "\n",
    "def longest_resize(img, max_h = None, max_w = None, upscale = False, interpolation = cv2.INTER_LINEAR):\n",
    "    if max_h is None and max_w is None:\n",
    "        return img\n",
    "    img_h, img_w = img.shape[:2]\n",
    "    r = min(max_h / img_h, max_w / img_w)\n",
    "    if not upscale:\n",
    "        r = min(1.0, r)\n",
    "    if r == 1.0:\n",
    "        return img\n",
    "    new_h, new_w = int(r * img_h), int(r * img_w)\n",
    "    img = cv2.resize(img, (new_w, new_h), interpolation)\n",
    "    return img\n",
    "\n",
    "\n",
    "def pad(img, new_h, new_w, pad_mode = 'top_left', pad_value = 'noise'):\n",
    "    ori_h, ori_w = img.shape[:2]\n",
    "    assert new_h >= ori_h and new_w >= ori_w\n",
    "    if pad_value == 'noise':\n",
    "        padded = np.random.rand(new_h, new_w, img.shape[2])\n",
    "        if img.dtype == np.uint8:\n",
    "            padded = (padded * 255).astype(np.uint8)\n",
    "        else:\n",
    "            padded = padded.astype(img.dtype)\n",
    "    if pad_mode == 'center':\n",
    "        pad_top = (new_h - ori_h) // 2\n",
    "        pad_left = (new_w - ori_w) // 2\n",
    "    elif pad_mode == 'top_left':\n",
    "        pad_top, pad_left = 0, 0\n",
    "    else:\n",
    "        raise ValueError\n",
    "    padded[pad_top:pad_top + ori_h, pad_left: pad_left + ori_w] = img\n",
    "    return padded\n",
    "\n",
    "\n",
    "def concat_imgs(imgs, max_h = None, max_w = None, axis = 1, border_width = 5, border_color = [255, 0, 255]):\n",
    "    hws = [img.shape[:2] for img in imgs]\n",
    "    src_max_h = max([hw[0] for hw in hws])\n",
    "    src_max_w = max([hw[1] for hw in hws])\n",
    "    max_h = min(max_h, src_max_h) if max_h is not None else src_max_h\n",
    "    max_w = min(max_w, src_max_w) if max_w is not None else src_max_w\n",
    "    r = min(max_h / src_max_h, max_w / src_max_w)\n",
    "    dst_max_h, dst_max_w = int(r * src_max_h), int(r * src_max_w)\n",
    "    \n",
    "    new_imgs = []\n",
    "    for i, img in enumerate(imgs):\n",
    "        h, w = img.shape[:2]\n",
    "        new_h, new_w = int(h * r), int(w * r)\n",
    "        new_img = cv2.resize(img, (new_w, new_h))\n",
    "        new_img = pad(new_img, dst_max_h, dst_max_w, pad_mode = 'top_left', pad_value = 'noise')\n",
    "        new_imgs.append(new_img)\n",
    "        if i != len(imgs) - 1:\n",
    "            _shape = list(new_img.shape)\n",
    "            _shape[axis] = border_width\n",
    "            border = np.zeros(_shape, dtype = new_img.dtype)\n",
    "            border_value = np.array(border_color, dtype = np.uint8)[None, None]\n",
    "            if border.dtype != np.uint8:\n",
    "                border_value = border_value / 255\n",
    "            border[..., :] = border_value\n",
    "                \n",
    "            new_imgs.append(border)\n",
    "    ret = np.concatenate(new_imgs, axis = axis)\n",
    "    return ret\n",
    "\n",
    "\n",
    "def float_to_uint8(imgs):\n",
    "    if isinstance(imgs, np.ndarray):\n",
    "        imgs = [imgs]\n",
    "    return [(255 * img).astype(np.uint8) for img in imgs]\n",
    "\n",
    "\n",
    "def display(img, max_h = None, max_w = None):\n",
    "    img = longest_resize(img, max_h, max_w)\n",
    "    if img.dtype != np.uint8:\n",
    "        img = (img * 255).astype(np.uint8)\n",
    "    idisplay(PIL.Image.fromarray(img))\n",
    "    \n",
    "\n",
    "def viz(imgs, transforms, max_h = 320, max_w = 320, assert_no_change=False):\n",
    "    if not isinstance(transforms, A.Compose):\n",
    "        transform = A.Compose(transforms, p = 1.0)\n",
    "    else:\n",
    "        transform = transforms\n",
    "    for img in imgs:\n",
    "        start = time.time()\n",
    "        ret = transform(image = img)\n",
    "        end = time.time()\n",
    "        print('Take:', round((end - start) * 1000), 'ms')\n",
    "        img2 = ret['image']\n",
    "        print(img2.dtype, img2.sum(), img2.min(), img2.max())\n",
    "\n",
    "        if img2.dtype != np.uint8:\n",
    "            print('Convert from float to uint8..')\n",
    "            _min = img2.min()\n",
    "            _max = img2.max()\n",
    "            if _min < 0.0 or _max > 1.0:\n",
    "                print(f'WARN: min={_min} max={_max}')\n",
    "                img2 = (img2 - _min) / (_max - _min)\n",
    "\n",
    "        eq = A.Equalize(mode='cv', by_channels=True, mask=None, mask_params=(), p=1.0)\n",
    "        img3 = eq(image = img2)['image']\n",
    "        \n",
    "        print(img.shape, img2.shape, img3.shape)\n",
    "        if assert_no_change:\n",
    "            assert img.shape == img2.shape\n",
    "            diff = np.sum(np.abs(img2 - img))\n",
    "            print('Diff:', diff)\n",
    "            assert diff == 0\n",
    "        if len(img.shape) == 2:\n",
    "            img = img[..., None].repeat(3, axis = -1)\n",
    "            img2 = img2[..., None].repeat(3, axis = -1)\n",
    "            img3 = img3[..., None].repeat(3, axis = -1)\n",
    "        elif len(img.shape) == 3:\n",
    "            pass\n",
    "        else:\n",
    "            raise AssertionError\n",
    "            \n",
    "        viz = concat_imgs([img, img2, img3], max_h = max_h, max_w = max_w)\n",
    "        if viz.dtype != np.uint8:\n",
    "            viz = (255 * viz).astype(np.uint8)\n",
    "        display(viz)\n",
    "        print('\\n----------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b21c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv('/home/dangnh36/datasets/.comp/byu/processed/gt_v3.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99143cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT_TOMO_IDS = ['tomo_1cc887', 'tomo_1ab322', 'tomo_ed1c97',\n",
    "                  'tomo_0a8f05', 'tomo_0363f2', 'tomo_10c564',\n",
    "                   'tomo_319f79', 'tomo_4555b6', 'tomo_868255',\n",
    "                   'tomo_b2ebbc', 'tomo_bede89', 'tomo_918e2b', \n",
    "                   'tomo_9c0253', 'tomo_b54396', 'tomo_dfc627'\n",
    "                  ]\n",
    "\n",
    "imgs = []\n",
    "for tomo_id in SELECT_TOMO_IDS:\n",
    "    row = df.filter(pl.col('tomo_id') == tomo_id)[0]\n",
    "    ori_spacing = float(row['voxel_spacing'][0])\n",
    "    img = cv2.imread(f'/home/dangnh36/datasets/.comp/byu/processed/viz/annotations/{tomo_id}.jpg')[..., 1]\n",
    "    ori_shape = img.shape\n",
    "    img = cv2.resize(img, None, fx = ori_spacing/16.0, fy = ori_spacing / 16.0)\n",
    "    print(tomo_id, ori_shape, '-->', img.shape)\n",
    "    imgs.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4d93db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c1bcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TEMPLATE, COPY THIS\n",
    "\n",
    "# transforms = [\n",
    "#     A.\n",
    "# ]\n",
    "# viz(imgs, transforms, max_h = 640, max_w = 640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8261b839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(A.Compose.main_compose)\n",
    "\n",
    "# a = A.Compose([A.HorizontalFlip(p=1.0)])\n",
    "# b = A.Compose([A.VerticalFlip(p=1.0)])\n",
    "# print(id(a.main_compose), id(b.main_compose))\n",
    "# print(A.Compose.main_compose, a.main_compose, b.main_compose)\n",
    "# a.main_compose = not a.main_compose\n",
    "# A.Compose.main_compose = not A.Compose.main_compose\n",
    "# print(A.Compose.main_compose, a.main_compose, a.__class__.main_compose, b.main_compose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9cac7b",
   "metadata": {},
   "source": [
    "## MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a61604e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read_func(p):\n",
    "    img = cv2.imread(p)\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#     img = img[..., 1]\n",
    "    return img\n",
    "\n",
    "\n",
    "random.seed(42)\n",
    "transforms = [\n",
    "   A.Perspective(\n",
    "        scale=(0.08, 0.08),\n",
    "        keep_size=False,\n",
    "        pad_mode=cv2.BORDER_CONSTANT,\n",
    "        pad_val=128,\n",
    "        fit_output=True,\n",
    "        interpolation=cv2.INTER_LINEAR,\n",
    "        p=1.0,\n",
    "    ),\n",
    "]\n",
    "\n",
    "viz(imgs[:3], transforms, max_h = 640, max_w = 640, assert_no_change=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e408a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417c200b-f33e-40ab-a4d0-4f5c1cf9e27d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a70de2-2dc8-4216-91bd-71387d855344",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b502abc3-6b61-4943-9a81-2a27d3113d78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b595f3e5-7cd0-44a9-8ffd-537c9b3295f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e0e716-8196-4890-bc41-c7fe06285863",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5494fe6b-51f1-466b-9f63-07ac2bf22f47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd80081-0451-45e5-a43e-c5d926dece20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd5b739-e2af-4084-a099-7c8762bca0df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b6ddaa-e708-4c71-8fef-542eedc02b53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb73cadc-5f8e-4acb-81b1-374af4c39588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9eaf832-c4f7-4c48-8b75-1303f11ceea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b567ff9-c469-419f-97d9-a29570bf1466",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eca6dc6-72f9-4e78-b7ea-ecde40bfb3f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f4f81c-fc66-4304-a415-5fafe6140640",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6b63b3-73d9-48c2-8937-889d9ba626cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c2c9de-068c-4d67-9e84-0020c91bdc0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b077802a-c00c-4d13-b40c-e179e39a8a82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a450909d-e345-40d0-82b5-fc5b321c8b2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc7a9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uint8 only, tile_grid_size=4,8,16,32\n",
    "A.CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), p = 1.0)\n",
    "\n",
    "# jitter on float32\n",
    "# Implement AdaptiveDownscale based on current resolution\n",
    "A.Downscale(scale_range=(0.4, 0.95),\n",
    "                interpolation_pair={'upscale': cv2.INTER_LANCZOS4, 'downscale': cv2.INTER_AREA}, p=1.0)\n",
    "\n",
    "# wrong on float32\n",
    "# good, but wrong result (bug?) when applied to float32 img\n",
    "A.Emboss(alpha=(0.3, 0.8), strength=(0.2, 0.8), p=1.0)\n",
    "\n",
    "# uint8 only\n",
    "# implement mask by spine curve\n",
    "# histogram equalization as fixed transformation?\n",
    "A.Equalize(mode='cv', by_channels=True, mask=None, mask_params=(), p=1.0)\n",
    "\n",
    "A.GaussNoise(var_limit=(10.0, 80.0), mean=0, per_channel=True, noise_scale_factor=1.0, p=1.0)\n",
    "\n",
    "\n",
    "# [OPTIONAL] use with caution\n",
    "# bug with input/ref is uint8 -> blank image returned\n",
    "# because of recent change in scikit-image update\n",
    "# ref: https://github.com/albumentations-team/albumentations/issues/1869\n",
    "# More: implement histogram matching with mask\n",
    "A.HistogramMatching(float_imgs, blend_ratio=(0.5, 1.0), read_fn=lambda x: x, p=1.0)\n",
    "\n",
    "\n",
    "A.ImageCompression(compression_type='jpeg', quality_range=(30, 95), p=1.0)\n",
    "\n",
    "\n",
    "A.MultiplicativeNoise(multiplier=(0.8, 1.2), per_channel=True, elementwise=True, p=1.0)\n",
    "\n",
    "\n",
    "# [OPTIONAL]\n",
    "A.PixelDistributionAdaptation(uint8_imgs,\n",
    "                              blend_ratio=(1.0, 1.0),\n",
    "                              read_fn=lambda x: x, transform_type='pca', p=1.0)\n",
    "\n",
    "A.Posterize(num_bits=4, p=1.0)\n",
    "\n",
    "# A.RandomBrightnessContrast(brightness_limit=(-0.1, 0.3), contrast_limit=(-0.4, 0.6), brightness_by_max=True, p=1.0)\n",
    "A.OneOf([\n",
    "    A.RandomBrightnessContrast(brightness_limit=(-0.1, 0.0), contrast_limit=(-0.2, 0.0), brightness_by_max=True, p=0.3 * 0.4),\n",
    "    A.RandomBrightnessContrast(brightness_limit=(-0.15, 0.0), contrast_limit=(0.0, 0.6), brightness_by_max=True, p=0.3 * 0.4),\n",
    "    A.RandomBrightnessContrast(brightness_limit=(0.0, 0.3), contrast_limit=(-0.4, 0.0), brightness_by_max=True, p=0.3 * 0.15),\n",
    "    A.RandomBrightnessContrast(brightness_limit=(0.0, 0.2), contrast_limit=(0.0, 0.5), brightness_by_max=True, p=0.3 * 0.05),\n",
    "    A.RandomBrightnessContrast(brightness_limit=(-0.3, 0.0), contrast_limit=(-0.2, 0.0), brightness_by_max=False, p=0.7 * 0.4),\n",
    "    A.RandomBrightnessContrast(brightness_limit=(-0.4, 0.0), contrast_limit=(0.0, 0.6), brightness_by_max=False, p=0.7 * 0.4),\n",
    "    A.RandomBrightnessContrast(brightness_limit=(0.0, 0.4), contrast_limit=(-0.4, 0.0), brightness_by_max=False, p=0.7 * 0.15),\n",
    "    A.RandomBrightnessContrast(brightness_limit=(0.0, 0.3), contrast_limit=(0.0, 0.5), brightness_by_max=False, p=0.7 * 0.05)\n",
    "], p=1.0)\n",
    "\n",
    "A.RandomGamma(gamma_limit=(60, 150), p=1.0)\n",
    "\n",
    "A.RandomToneCurve(scale=0.4, per_channel=True, p=1.0)\n",
    "\n",
    "A.Sharpen(alpha=(0.1, 0.4), lightness=(0.0, 0.4), always_apply=None, p=1.0)\n",
    "\n",
    "\n",
    "A.RandomSizedBBoxSafeCrop(height, width, erosion_rate=0.0, interpolation=1, always_apply=None, p=1.0)\n",
    "\n",
    "\n",
    "\n",
    "A.CoarseDropout(max_holes=None, max_height=None, max_width=None, min_holes=None, min_height=None, min_width=None, fill_value=0, mask_fill_value=None, num_holes_range=(1, 1), hole_height_range=(8, 8), hole_width_range=(8, 8), always_apply=None, p=0.5)\n",
    "\n",
    "A.GridDropout(ratio=0.8, random_offset=False, fill_value=0, mask_fill_value=None, unit_size_range=(50, 50), holes_number_xy=(5, 5), shift_xy=(0, 0),p=1.0)\n",
    "\n",
    "# [IGNORE] JUST TRY TO ADD IT :), add to see if it downgrade performance as expected\n",
    "HorizontalFlip(p=1.0)\n",
    "VerticalFlip(p=1.0)\n",
    "\n",
    "LongestMaxSize(max_size=512, interpolation=cv2.INTER_LINEAR, p=1.0)\n",
    "A.PadIfNeeded(min_height=512, min_width=512, pad_height_divisor=None, pad_width_divisor=None, position='center',\n",
    "                  border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=None, p=1.0)\n",
    "\n",
    "# very slow\n",
    "# could reduce localization acc\n",
    "# how to deal with out-of-image keypoints\n",
    "# implement: if dist > keypoints_threshold, then roll back to NoOp\n",
    "A.OneOf([\n",
    "    A.PiecewiseAffine(scale=(0.025, 0.025), nb_rows=4, nb_cols=4, interpolation=cv2.INTER_LINEAR, mask_interpolation=0, cval=0, cval_mask=0, mode='constant', absolute_scale=False, keypoints_threshold=0.01, p=1.0),\n",
    "    A.PiecewiseAffine(scale=(0.016, 0.016), nb_rows=6, nb_cols=6, interpolation=cv2.INTER_LINEAR, mask_interpolation=0, cval=0, cval_mask=0, mode='constant', absolute_scale=False, keypoints_threshold=0.01, p=1.0)\n",
    "    A.PiecewiseAffine(scale=(0.0125, 0.0125), nb_rows=8, nb_cols=8, interpolation=cv2.INTER_LINEAR, mask_interpolation=0, cval=0, cval_mask=0, mode='constant', absolute_scale=False, keypoints_threshold=0.01, p=1.0),  \n",
    "])\n",
    "\n",
    "AA.RandomResizedCropNoResize\n",
    "\n",
    "# Dangerous since length is provided in pixels\n",
    "# Modify so that length is fraction of width/height\n",
    "A.XYMasking(num_masks_x=(3,3), num_masks_y=(4,4), mask_x_length=(5, 5), mask_y_length=(10, 10), fill_value=0, mask_fill_value=0, p=1.0)\n",
    "\n",
    "##################################\n",
    "# PARAMETERIZED\n",
    "\n",
    "A.OneOf([\n",
    "    # rotate only\n",
    "    A.Affine(scale={'x': (0.6, 1.2), 'y': (0.6, 1.2)},\n",
    "             translate_percent={'x': (-0.25, 0.25), 'y': (-0.4, 0.0)},\n",
    "             rotate=(-30, 30), \n",
    "             shear={'x': (-10, 10), 'y': (-5, 5)},\n",
    "             interpolation=cv2.INTER_LINEAR, cval=0, mode=cv2.BORDER_CONSTANT, fit_output=False, keep_ratio=False, balanced_scale=True, p=1.0),\n",
    "    # shear only\n",
    "    A.Affine(scale={'x': (0.6, 1.2), 'y': (0.6, 1.2)},\n",
    "             translate_percent={'x': (-0.25, 0.25), 'y': (-0.4, 0.0)},\n",
    "             rotate=(-10, 10),\n",
    "             shear={'x': (-30, 30), 'y': (-30, 30)},\n",
    "             interpolation=cv2.INTER_LINEAR, cval=0, mode=cv2.BORDER_CONSTANT, fit_output=False, keep_ratio=False, balanced_scale=True, p=1.0)\n",
    "], p=1.0)\n",
    "\n",
    "# identical to Affine with less functionals: scale for x/y separately, shear\n",
    "A.ShiftScaleRotate(scale_limit=(-0.4, 0.2), rotate_limit=(-30, 30), interpolation=cv2.INTER_LINEAR, border_mode=cv2.BORDER_CONSTANT, value=0, shift_limit_x=(-0.25, 0.25), shift_limit_y=(-0.4, 0.0), p=1.0)\n",
    "\n",
    "A.Perspective(scale=(0.05, 0.1), keep_size=False, pad_mode=cv2.BORDER_CONSTANT, pad_val=0, fit_output=True, interpolation=cv2.INTER_LINEAR, p=1.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e5fb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "341 - 183, 577 - 260"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690f3538",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30eb644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54882410",
   "metadata": {},
   "source": [
    "## NOTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7006686d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c49e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b052ebea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffe3718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b390ea69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2aa820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [OPTIONAL] use with caution\n",
    "# bug with input/ref is uint8 -> blank image returned\n",
    "# because of recent change in scikit-image update\n",
    "# ref: https://github.com/albumentations-team/albumentations/issues/1869\n",
    "# More: implement histogram matching with mask\n",
    "A.HistogramMatching(float_imgs, blend_ratio=(0.5, 1.0), read_fn=lambda x: x, p=1.0)\n",
    "\n",
    "# [OPTIONAL]\n",
    "A.PixelDistributionAdaptation(uint8_imgs,\n",
    "                              blend_ratio=(1.0, 1.0),\n",
    "                              read_fn=lambda x: x, transform_type='pca', p=1.0)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd10b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a32e0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "def get_vb_union_bbox(params, data, filter_vb_ids = [0], x_include_all = True, y_lowest_offset = True):\n",
    "#     print('params:', params)\n",
    "#     print('data:', data)\n",
    "    assert len(data['keypoints']) == len(data['keypoint_classes']) == len(data['keypoint_weights'])\n",
    "    img_h, img_w = params['shape'][:2]\n",
    "    \n",
    "    xs = []\n",
    "    ys = []\n",
    "    vb_ids = []\n",
    "    min_x = img_w\n",
    "    max_x = 0\n",
    "    min_y = img_h\n",
    "    max_y = 0\n",
    "    for kpt, kpt_cls, kpt_weight in zip(data['keypoints'], data['keypoint_classes'], data['keypoint_weights']):\n",
    "        if kpt_weight == -1 or kpt_cls == -1:\n",
    "            continue\n",
    "        min_x = min(min_x, kpt[0])\n",
    "        max_x = max(max_x, kpt[0])\n",
    "        min_y = min(min_y, kpt[1])\n",
    "        max_y = max(max_y, kpt[1])\n",
    "        vb_id = kpt_cls // 4\n",
    "        if vb_id not in filter_vb_ids:\n",
    "            continue\n",
    "        # xy\n",
    "        xs.append(kpt[0])\n",
    "        ys.append(kpt[1])\n",
    "        vb_ids.append(vb_id)\n",
    "    if vb_ids:\n",
    "        if y_lowest_offset:\n",
    "            lowest_vb_id = min(vb_ids)\n",
    "            lowest_vb_poly = [(xs[j], ys[j]) for j, vb_id in enumerate(vb_ids) if vb_id == lowest_vb_id]\n",
    "            try:\n",
    "                lowest_vb_area = Polygon(lowest_vb_poly).area\n",
    "                delta_y = (lowest_vb_area ** 0.5) / 2\n",
    "            except:\n",
    "                delta_y = 0\n",
    "        else:\n",
    "            delta_y = 0\n",
    "        assert delta_y >=0\n",
    "        if x_include_all:\n",
    "            ret = min_x, min(ys), max_x, max(ys) + delta_y\n",
    "        else:\n",
    "            ret = min(xs), min(ys), max(xs), max(ys) + delta_y\n",
    "    else:\n",
    "        ret = min_x, min_y, max_x, max_y\n",
    "    print('keep bbox:', ret)\n",
    "    return ret\n",
    "\n",
    "\n",
    "AC.CustomRandomSizedBBoxSafeCrop(scale=(0.25, 1.0), ratio=(0.25, 1.5),\n",
    "                                 get_bbox_func = partial(get_vb_union_bbox, filter_vb_ids = [0], x_include_all = True, y_lowest_offset = True),\n",
    "                                 retry=30, p=1.0)\n",
    "\n",
    "\n",
    "AC.CustomCoarseDropout(fill_value=0, num_holes_range=(4, 8), hole_height_range=(0.1, 0.2), \n",
    "                hole_width_range=(0.1, 0.2), p=1.0)\n",
    "AC.CustomGridDropout(ratio=0.5, random_offset=True, fill_value=0,\n",
    "              holes_number_xy=((3, 8), (3, 8)), p=1.0)\n",
    "\n",
    "AC.CustomXYMasking(num_masks_x=(2,5), num_masks_y=(2,5),\n",
    "                mask_x_length=(0.03, 0.05), mask_y_length=(0.03, 0.05),\n",
    "                fill_value=0, p=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad0c8ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549a3dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "augment = A.Compose([\n",
    "    # crop\n",
    "    AA.RandomResizedBBoxSafeCropNoResize(p=0.4),\n",
    "\n",
    "    # flip\n",
    "    A.HorizontalFlip(p=0.0),\n",
    "    A.VerticalFlip(p=0.0),\n",
    "\n",
    "    # noise\n",
    "    A.OneOf([\n",
    "        A.GaussNoise(var_limit=(10.0, 80.0), mean=0, per_channel=True, noise_scale_factor=1.0, p=1.0),\n",
    "        A.MultiplicativeNoise(multiplier=(0.8, 1.2), per_channel=True, elementwise=True, p=1.0),\n",
    "    ], p = 1.0),\n",
    "\n",
    "    # reduce quality\n",
    "    A.OneOf([\n",
    "        # jitter on float32, implement AdaptiveDownscale based on current resolution\n",
    "        A.Downscale(scale_range=(0.4, 0.95), interpolation_pair={'upscale': cv2.INTER_LANCZOS4, 'downscale': cv2.INTER_AREA}, p=1.0),\n",
    "        A.ImageCompression(compression_type='jpeg', quality_range=(30, 95), p=1.0),\n",
    "        A.Posterize(num_bits=4, p=1.0), \n",
    "    ], p=1.0),\n",
    "\n",
    "    # texture, contrast\n",
    "    A.OneOf([\n",
    "        # wrong on float32 img\n",
    "        A.Emboss(alpha=(0.3, 0.8), strength=(0.2, 0.8), p=1.0),\n",
    "        A.Sharpen(alpha=(0.1, 0.4), lightness=(0.0, 0.4), p=1.0),\n",
    "        A.OneOf([\n",
    "            A.CLAHE(clip_limit=4.0, tile_grid_size=(4, 4), p = 1.0),\n",
    "            A.CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), p = 1.0),\n",
    "            A.CLAHE(clip_limit=4.0, tile_grid_size=(16, 16), p = 1.0),\n",
    "        ], p=1.0)\n",
    "    ], p=1.0),\n",
    "    \n",
    "    # color\n",
    "    A.OneOf([\n",
    "        A.OneOf([\n",
    "            A.RandomBrightnessContrast(brightness_limit=(-0.1, 0.0), contrast_limit=(-0.2, 0.0), brightness_by_max=True, p=0.3 * 0.4),\n",
    "            A.RandomBrightnessContrast(brightness_limit=(-0.15, 0.0), contrast_limit=(0.0, 0.6), brightness_by_max=True, p=0.3 * 0.4),\n",
    "            A.RandomBrightnessContrast(brightness_limit=(0.0, 0.3), contrast_limit=(-0.4, 0.0), brightness_by_max=True, p=0.3 * 0.15),\n",
    "            A.RandomBrightnessContrast(brightness_limit=(0.0, 0.2), contrast_limit=(0.0, 0.5), brightness_by_max=True, p=0.3 * 0.05),\n",
    "            A.RandomBrightnessContrast(brightness_limit=(-0.3, 0.0), contrast_limit=(-0.2, 0.0), brightness_by_max=False, p=0.7 * 0.4),\n",
    "            A.RandomBrightnessContrast(brightness_limit=(-0.4, 0.0), contrast_limit=(0.0, 0.6), brightness_by_max=False, p=0.7 * 0.4),\n",
    "            A.RandomBrightnessContrast(brightness_limit=(0.0, 0.4), contrast_limit=(-0.4, 0.0), brightness_by_max=False, p=0.7 * 0.15),\n",
    "            A.RandomBrightnessContrast(brightness_limit=(0.0, 0.3), contrast_limit=(0.0, 0.5), brightness_by_max=False, p=0.7 * 0.05)\n",
    "        ], p=1.0),\n",
    "        A.RandomToneCurve(scale=0.4, per_channel=True, p=1.0),\n",
    "        A.RandomGamma(gamma_limit=(60, 150), p=1.0)\n",
    "    ]),\n",
    "\n",
    "    # geometric\n",
    "    A.OneOf([\n",
    "        A.OneOf([\n",
    "            # rotate only\n",
    "            A.Affine(scale={'x': (0.6, 1.2), 'y': (0.6, 1.2)},\n",
    "                     translate_percent={'x': (-0.25, 0.25), 'y': (-0.4, 0.0)},\n",
    "                     rotate=(-30, 30), shear={'x': (-10, 10), 'y': (-5, 5)},\n",
    "                     interpolation=cv2.INTER_LINEAR, cval=0, mode=cv2.BORDER_CONSTANT, fit_output=False, keep_ratio=False, balanced_scale=True, p=1.0),\n",
    "            # shear only\n",
    "            A.Affine(scale={'x': (0.6, 1.2), 'y': (0.6, 1.2)},\n",
    "                     translate_percent={'x': (-0.25, 0.25), 'y': (-0.4, 0.0)},\n",
    "                     rotate=(-10, 10), shear={'x': (-30, 30), 'y': (-30, 30)},\n",
    "                     interpolation=cv2.INTER_LINEAR, cval=0, mode=cv2.BORDER_CONSTANT, fit_output=False, keep_ratio=False, balanced_scale=True, p=1.0)\n",
    "        ], p=1.0),\n",
    "        # identical to Affine with less functionals: scale for x/y separately, shear\n",
    "        A.ShiftScaleRotate(scale_limit=(-0.4, 0.2), rotate_limit=(-30, 30), interpolation=cv2.INTER_LINEAR, border_mode=cv2.BORDER_CONSTANT, value=0, shift_limit_x=(-0.25, 0.25), shift_limit_y=(-0.4, 0.0), p=0.0),\n",
    "        A.Perspective(scale=(0.05, 0.1), keep_size=False, pad_mode=cv2.BORDER_CONSTANT, pad_val=0, fit_output=True, interpolation=cv2.INTER_LINEAR, p=1.0),\n",
    "        # very slow + in-accurate keypoints\n",
    "        # how to deal with out-of-image keypoints ?\n",
    "        # implement: if dist > keypoints_threshold, then roll back to NoOp\n",
    "        A.OneOf([\n",
    "            A.PiecewiseAffine(scale=(0.025, 0.025), nb_rows=4, nb_cols=4, interpolation=cv2.INTER_LINEAR, mask_interpolation=0, cval=0, cval_mask=0, mode='constant', absolute_scale=False, keypoints_threshold=0.01, p=1.0),\n",
    "            A.PiecewiseAffine(scale=(0.016, 0.016), nb_rows=6, nb_cols=6, interpolation=cv2.INTER_LINEAR, mask_interpolation=0, cval=0, cval_mask=0, mode='constant', absolute_scale=False, keypoints_threshold=0.01, p=1.0)\n",
    "            A.PiecewiseAffine(scale=(0.0125, 0.0125), nb_rows=8, nb_cols=8, interpolation=cv2.INTER_LINEAR, mask_interpolation=0, cval=0, cval_mask=0, mode='constant', absolute_scale=False, keypoints_threshold=0.01, p=1.0)\n",
    "        ], p=1.0)\n",
    "    ], p=1.0),\n",
    "\n",
    "    # # dropout\n",
    "    # A.OneOf([\n",
    "        \n",
    "    # ], p=1.0)\n",
    "], p = 1.0)\n",
    "\n",
    "\n",
    "transform = A.Compose([\n",
    "    # histogram equalization as fixed transformation?\n",
    "    A.Equalize(mode='cv', by_channels=True, mask=None, mask_params=(), p=1.0),\n",
    "    A.LongestMaxSize(max_size=512, interpolation=cv2.INTER_LINEAR, p=1.0),\n",
    "    A.PadIfNeeded(min_height=512, min_width=512, pad_height_divisor=None, pad_width_divisor=None, position='top_left',\n",
    "                  border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=None, p=1.0)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74660075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read_func(p):\n",
    "    img = cv2.imread(p)\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#     img = img[..., 1]\n",
    "    return img\n",
    "\n",
    "from functools import partial\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "def get_vb_union_bbox(params, data, filter_vb_ids = [0], x_include_all = True, y_lowest_offset = True):\n",
    "    # print('params:', params)\n",
    "#     print('data:', data)\n",
    "    assert len(data['keypoints']) == len(data['keypoint_classes']) == len(data['keypoint_weights'])\n",
    "    img_h, img_w = params['shape'][:2]\n",
    "    \n",
    "    xs = []\n",
    "    ys = []\n",
    "    vb_ids = []\n",
    "    min_x = img_w\n",
    "    max_x = 0\n",
    "    min_y = img_h\n",
    "    max_y = 0\n",
    "    for kpt, kpt_cls, kpt_weight in zip(data['keypoints'], data['keypoint_classes'], data['keypoint_weights']):\n",
    "        if kpt_weight == -1 or kpt_cls == -1:\n",
    "            continue\n",
    "        min_x = min(min_x, kpt[0])\n",
    "        max_x = max(max_x, kpt[0])\n",
    "        min_y = min(min_y, kpt[1])\n",
    "        max_y = max(max_y, kpt[1])\n",
    "        vb_id = kpt_cls // 4\n",
    "        if vb_id not in filter_vb_ids:\n",
    "            continue\n",
    "        # xy\n",
    "        xs.append(kpt[0])\n",
    "        ys.append(kpt[1])\n",
    "        vb_ids.append(vb_id)\n",
    "    if vb_ids:\n",
    "        if y_lowest_offset:\n",
    "            lowest_vb_id = min(vb_ids)\n",
    "            lowest_vb_poly = [(xs[j], ys[j]) for j, vb_id in enumerate(vb_ids) if vb_id == lowest_vb_id]\n",
    "            try:\n",
    "                lowest_vb_area = Polygon(lowest_vb_poly).area\n",
    "                delta_y = (lowest_vb_area ** 0.5) / 2\n",
    "            except:\n",
    "                delta_y = 0\n",
    "        else:\n",
    "            delta_y = 0\n",
    "        assert delta_y >=0\n",
    "        if x_include_all:\n",
    "            ret = min_x, min(ys), max_x, max(ys) + delta_y\n",
    "        else:\n",
    "            ret = min(xs), min(ys), max(xs), max(ys) + delta_y\n",
    "    else:\n",
    "        ret = min_x, min_y, max_x, max_y\n",
    "    print('keep bbox:', ret)\n",
    "    return ret\n",
    "\n",
    "random.seed(611)\n",
    "transforms = [\n",
    "    AC.CustomRandomSizedBBoxSafeCrop(scale=(0.25, 1.0), ratio=(0.25, 1.5),\n",
    "                                     get_bbox_func = partial(get_vb_union_bbox, filter_vb_ids = [0], x_include_all = True, y_lowest_offset = True),\n",
    "                                     retry=30, p=1.0)\n",
    "]\n",
    "viz(\n",
    "    # float_imgs,\n",
    "    uint8_imgs,\n",
    "    # rgb_uint8_imgs,\n",
    "    all_keypoints,\n",
    "    transforms, max_h = 640, max_w = 640, assert_no_change=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947f85e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf37c4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.4 * 0.6 + 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddf5c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.6 * 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a63881",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc573250",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8561470,
     "sourceId": 71549,
     "sourceType": "competition"
    },
    {
     "databundleVersionId": 9658398,
     "datasetId": 5533963,
     "sourceId": 9451652,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 9631557,
     "datasetId": 5726651,
     "sourceId": 9427038,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30761,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
