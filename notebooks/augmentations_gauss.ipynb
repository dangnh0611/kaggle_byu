{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca379aa-458c-4400-a2ee-dcba244b12a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copick\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import zarr\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import polars as pl\n",
    "from itkwidgets import view\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "\n",
    "from czii.utils.data import parse_tomo_kpts_pair\n",
    "from czii.utils.constant import PARTICLE_RADIUS as _PARTICLE_RADIUS\n",
    "from czii.utils.constant import SCALE_ZYX, SCALE_X, SCALE_Y, SCALE_Z\n",
    "from monai import transforms as T\n",
    "from czii.data.transform import monai_custom as CT\n",
    "\n",
    "# from monai.visualize import blend_images, matshow3d, plot_2d_or_3d_image\n",
    "\n",
    "LAZY = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72de6575-f0fc-4bfa-899e-8cccf55a8c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import PIL\n",
    "from IPython.display import Image\n",
    "from IPython.display import display as idisplay\n",
    "import random\n",
    "\n",
    "def describe(df):\n",
    "    with pl.Config(tbl_rows = 30):\n",
    "        display(df.describe(percentiles = PERCENTILES))\n",
    "        \n",
    "\n",
    "def longest_resize(img, max_h = None, max_w = None, upscale = False, interpolation = cv2.INTER_LINEAR):\n",
    "    if max_h is None and max_w is None:\n",
    "        return img\n",
    "    img_h, img_w = img.shape[:2]\n",
    "    _ratios = []\n",
    "    if max_h is not None:\n",
    "        _ratios.append(max_h / img_h)\n",
    "    if max_w is not None:\n",
    "        _ratios.append(max_w / img_w)\n",
    "    r = min(_ratios)\n",
    "    if not upscale:\n",
    "        r = min(1.0, r)\n",
    "    if r == 1.0:\n",
    "        return img\n",
    "    new_h, new_w = int(r * img_h), int(r * img_w)\n",
    "    img = cv2.resize(img, (new_w, new_h), interpolation)\n",
    "    return img\n",
    "\n",
    "\n",
    "def pad(img, new_h, new_w, pad_mode = 'top_left', pad_value = 'noise'):\n",
    "    ori_h, ori_w = img.shape[:2]\n",
    "    assert new_h >= ori_h and new_w >= ori_w\n",
    "    if pad_value == 'noise':\n",
    "        padded = np.random.rand(new_h, new_w, img.shape[2])\n",
    "        if img.dtype == np.uint8:\n",
    "            padded = (padded * 255).astype(np.uint8)\n",
    "        else:\n",
    "            padded = padded.astype(img.dtype)\n",
    "    if pad_mode == 'center':\n",
    "        pad_top = (new_h - ori_h) // 2\n",
    "        pad_left = (new_w - ori_w) // 2\n",
    "    elif pad_mode == 'top_left':\n",
    "        pad_top, pad_left = 0, 0\n",
    "    else:\n",
    "        raise ValueError\n",
    "    padded[pad_top:pad_top + ori_h, pad_left: pad_left + ori_w] = img\n",
    "    return padded\n",
    "\n",
    "\n",
    "def concat_imgs(imgs, max_h = None, max_w = None, axis = 1, border_width = 5, border_color = [255, 0, 255]):\n",
    "    hws = [img.shape[:2] for img in imgs]\n",
    "    src_max_h = max([hw[0] for hw in hws])\n",
    "    src_max_w = max([hw[1] for hw in hws])\n",
    "    max_h = min(max_h, src_max_h) if max_h is not None else src_max_h\n",
    "    max_w = min(max_w, src_max_w) if max_w is not None else src_max_w\n",
    "    r = min(max_h / src_max_h, max_w / src_max_w)\n",
    "    dst_max_h, dst_max_w = int(r * src_max_h), int(r * src_max_w)\n",
    "\n",
    "    new_imgs = []\n",
    "    for i, img in enumerate(imgs):\n",
    "        h, w = img.shape[:2]\n",
    "        new_h, new_w = int(h * r), int(w * r)\n",
    "        new_img = cv2.resize(img, (new_w, new_h))\n",
    "        if len(new_img.shape) < 3:\n",
    "            assert len(new_img.shape) == 2\n",
    "            new_img = new_img[..., None]\n",
    "        new_img = pad(new_img, dst_max_h, dst_max_w, pad_mode = 'top_left', pad_value = 'noise')\n",
    "        new_imgs.append(new_img)\n",
    "        if i != len(imgs) - 1:\n",
    "            _shape = list(new_img.shape)\n",
    "            _shape[axis] = border_width\n",
    "            border = np.zeros(_shape, dtype = new_img.dtype)\n",
    "            border_value = np.array(border_color, dtype = np.uint8)[None, None]\n",
    "            if border.dtype != np.uint8:\n",
    "                border_value = border_value / 255\n",
    "            border[..., :] = border_value\n",
    "            new_imgs.append(border)\n",
    "    ret = np.concatenate(new_imgs, axis = axis)\n",
    "    return ret\n",
    "\n",
    "\n",
    "def float_to_uint8(imgs):\n",
    "    if isinstance(imgs, np.ndarray):\n",
    "        imgs = [imgs]\n",
    "    return [(255 * img).astype(np.uint8) for img in imgs]\n",
    "\n",
    "def display_img(img, max_h = None, max_w = None):\n",
    "    img = longest_resize(img, max_h, max_w)\n",
    "    if img.dtype != np.uint8:\n",
    "        img = (img * 255).astype(np.uint8)\n",
    "    idisplay(PIL.Image.fromarray(img))\n",
    "\n",
    "def select(tomo, num_slices, axis = 'z'):\n",
    "    assert len(tomo.shape) == 3 and num_slices >= 1\n",
    "    axis = {'z': 0, 'y': 1, 'x': 2}[axis]\n",
    "    slices = [slice(None), slice(None), slice(None)]\n",
    "    # main_slice = slice(0, tomo.shape[axis], (tomo.shape[axis] - 1) // (num_slices - 1))\n",
    "    main_slice = list(range(0, tomo.shape[axis], (tomo.shape[axis] - 1) // (num_slices - 1)))\n",
    "    slices[axis] = main_slice\n",
    "    # print('SLICES:', slices)\n",
    "    tomo = tomo[*slices]\n",
    "    permute = [0, 1, 2]\n",
    "    permute.remove(axis)\n",
    "    new_permute = [axis, *permute]\n",
    "    tomo = np.transpose(tomo, new_permute)\n",
    "    return tomo, main_slice\n",
    "\n",
    "\n",
    "def get_norm_func(norm_type = 'sample_min_max'):\n",
    "    # Transform\n",
    "    if norm_type == \"sample_min_max\":\n",
    "        normalize_transform = T.ScaleIntensityd(\n",
    "            keys=[\"image\"],\n",
    "            minv=0.0,\n",
    "            maxv=1.0,\n",
    "            factor=None,\n",
    "            channel_wise=False,\n",
    "            dtype=None,\n",
    "        )\n",
    "    elif norm_type == \"sample_mean_std\":\n",
    "        normalize_transform = T.NormalizeIntensityd(\n",
    "            keys=[\"image\"],\n",
    "            subtrahend=None,\n",
    "            divisor=None,\n",
    "            nonzero=False,\n",
    "            channel_wise=False,\n",
    "        )\n",
    "    elif norm_type == \"global_mean_std\":\n",
    "        normalize_transform = T.NormalizeIntensityd(\n",
    "            keys=[\"image\"],\n",
    "            subtrahend=5.257659e-08,\n",
    "            divisor=7.199923e-06,\n",
    "            nonzero=False,\n",
    "            channel_wise=False,\n",
    "        )\n",
    "    elif norm_type.startswith(\"sample_percentile\"):\n",
    "        postfix = norm_type.replace('sample_percentile', '', 1)\n",
    "        if postfix == '':\n",
    "            clip = False\n",
    "        elif postfix == '_clip':\n",
    "            clip = True\n",
    "        else:\n",
    "            raise ValueError\n",
    "        normalize_transform = T.ScaleIntensityRangePercentilesd(\n",
    "            keys=[\"image\"],\n",
    "            lower=5,\n",
    "            upper=95,\n",
    "            b_min=0.0,\n",
    "            b_max=1.0,\n",
    "            clip=clip,\n",
    "            relative=True,\n",
    "            channel_wise=False,\n",
    "        )\n",
    "    elif norm_type == \"sample_hist_equalize\":\n",
    "        normalize_transform = T.HistogramNormalized(\n",
    "            keys=[\"image\"], num_bins=256, min=0.0, max=1.0\n",
    "        )\n",
    "    elif norm_type == 'log_percentile':\n",
    "        def _func(image):\n",
    "            image = np.log(image - image.min())\n",
    "            low = np.percentile(image, 5)\n",
    "            top = np.percentile(image, 95)\n",
    "            print(image.min(), low, top, image.max())\n",
    "            return np.clip(image, a_min=low, a_max=top)\n",
    "        return _func\n",
    "    elif norm_type == 'log_sign':\n",
    "        return lambda image: np.log(np.abs(image) + 1e-8) * np.sign(image)\n",
    "    elif norm_type == 'log_abs':\n",
    "        return lambda image: np.log(np.abs(image) + 1e-8)\n",
    "    else:\n",
    "        raise ValueError\n",
    "    return lambda image: normalize_transform({'image': image[None]})['image'][0]\n",
    "\n",
    "\n",
    "from typing import Tuple\n",
    "def crop_kpts(\n",
    "    kpts: torch.Tensor, crop_start: Tuple[int, int, int], crop_end: Tuple[int, int, int]\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Crop keypoints: remove out-of-regions ones, then offset valid one due to cropping\n",
    "\n",
    "    Args:\n",
    "        kpts: (N, D), where typically D>=3, the first 3 dimensions are Z, Y, X coordinate\n",
    "        crop_start: starting coordinate of length 3 for Z, Y, X\n",
    "        crop_end: ending coordinate of length 3 for Z, Y, X\n",
    "\n",
    "    Returns:\n",
    "        Cropped keypoints with length <= input keypoints\n",
    "    \"\"\"\n",
    "    crop_start = torch.tensor(crop_start)[None]\n",
    "    crop_end = torch.tensor(crop_end)[None]\n",
    "    assert crop_start.shape == crop_end.shape == (1, 3)\n",
    "    assert kpts.ndim == 2 and kpts.shape[1] >= 3\n",
    "    keep = torch.all(\n",
    "        torch.logical_and(kpts[:, :3] >= crop_start, kpts[:, :3] <= crop_end), dim=1\n",
    "    )\n",
    "    kpts = kpts[keep]\n",
    "    kpts[:, :3] = kpts[:, :3] - crop_start\n",
    "    return kpts\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "import heapq\n",
    "\n",
    "def select_top_k_unique_keypoints(keypoints, K):\n",
    "    \"\"\"\n",
    "    Selects top K keypoints such that:\n",
    "    - The planes z, y, x passing through these keypoints cover the maximum number of other keypoints.\n",
    "    - Each z, y, x coordinate of the selected keypoints is unique.\n",
    "\n",
    "    Args:\n",
    "        keypoints (list of tuple): List of 3D integer coordinates (z, y, x).\n",
    "        K (int): Number of keypoints to select.\n",
    "\n",
    "    Returns:\n",
    "        list of tuple: Top K keypoints with unique z, y, and x coordinates.\n",
    "    \"\"\"\n",
    "    # Initialize counters for keypoint coverage by planes\n",
    "    z_counter = Counter()\n",
    "    y_counter = Counter()\n",
    "    x_counter = Counter()\n",
    "\n",
    "    # Count how many keypoints are covered by each plane\n",
    "    for z, y, x in keypoints:\n",
    "        z_counter[z] += 1\n",
    "        y_counter[y] += 1\n",
    "        x_counter[x] += 1\n",
    "\n",
    "    # Calculate the coverage score for each keypoint\n",
    "    keypoint_scores = []\n",
    "    for z, y, x in keypoints:\n",
    "        score = z_counter[z] + y_counter[y] + x_counter[x] - 2  # Avoid double counting the keypoint itself\n",
    "        keypoint_scores.append((score, (z, y, x)))\n",
    "\n",
    "    # Sort keypoints by score in descending order\n",
    "    keypoint_scores.sort(reverse=True, key=lambda item: item[0])\n",
    "\n",
    "    # Select the top K keypoints with unique z, y, and x coordinates\n",
    "    selected_keypoints = []\n",
    "    used_z = set()\n",
    "    used_y = set()\n",
    "    used_x = set()\n",
    "\n",
    "    for _, (z, y, x) in keypoint_scores:\n",
    "        if z not in used_z and y not in used_y and x not in used_x:\n",
    "            selected_keypoints.append((z, y, x))\n",
    "            used_z.add(z)\n",
    "            used_y.add(y)\n",
    "            used_x.add(x)\n",
    "            if len(selected_keypoints) == K:\n",
    "                break\n",
    "\n",
    "    return selected_keypoints\n",
    "\n",
    "\n",
    "COLORS = [\n",
    "    (255, 0, 0),      # Red\n",
    "    (0, 255, 0),      # Green\n",
    "    (0, 0, 255),      # Blue\n",
    "    (0, 255, 255),    # Cyan\n",
    "    (255, 0, 255),    # Magenta\n",
    "    (255, 255, 0)     # Yellow\n",
    "]\n",
    "AXIS_COLORS = [\n",
    "    (255, 0, 0),\n",
    "    (0, 255, 0),\n",
    "    (0, 0, 255)\n",
    "]\n",
    "\n",
    "\n",
    "def draw_ellipse_from_normal_distribution(image, mean, cov, color=(255, 0, 0), thickness=2, expand=1.5):\n",
    "    \"\"\"\n",
    "    Draws an ellipse representing a 2D normal distribution on a given image.\n",
    "    \n",
    "    Args:\n",
    "        image (np.ndarray): The image on which to draw the ellipse.\n",
    "        mean (tuple): Mean vector (x, y) of the 2D normal distribution.\n",
    "        cov (np.ndarray): 2x2 covariance matrix.\n",
    "        color (tuple): Color of the ellipse (B, G, R).\n",
    "        thickness (int): Thickness of the ellipse.\n",
    "    \"\"\"\n",
    "    # Compute eigenvalues and eigenvectors of the covariance matrix\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(cov)\n",
    "    \n",
    "    # Get the angle of rotation from the eigenvectors\n",
    "    angle = np.degrees(np.arctan2(eigenvectors[1, 0], eigenvectors[0, 0]))\n",
    "    \n",
    "    # Get the lengths of the axes\n",
    "    axis_length = np.sqrt(eigenvalues) * expand\n",
    "    \n",
    "    # Convert mean to integer tuple for OpenCV\n",
    "    center = tuple(map(int, mean))\n",
    "    \n",
    "    # Draw the ellipse\n",
    "    cv2.ellipse(\n",
    "        image,\n",
    "        center,\n",
    "        (int(axis_length[0]), int(axis_length[1])),  # Major and minor axes\n",
    "        angle,\n",
    "        0, 360,\n",
    "        color,\n",
    "        thickness\n",
    "    )\n",
    "    \n",
    "\n",
    "def viz_transform(all_tomos, all_kpts, transforms, seed = None, view_3d = False):\n",
    "    assert len(all_tomos) == len(all_kpts)\n",
    "    transform = T.Compose(\n",
    "        [\n",
    "            T.ScaleIntensityRangePercentilesd(\n",
    "                keys=[\"image\"],\n",
    "                lower=5,\n",
    "                upper=95,\n",
    "                b_min=0.0,\n",
    "                b_max=1.0,\n",
    "                clip=True,\n",
    "                relative=False,\n",
    "                channel_wise=False,\n",
    "            ),\n",
    "            *transforms,\n",
    "            CT.ApplyTransformToNormalDistributionsd(\n",
    "                keys=[\"kpts\"],\n",
    "                refer_keys=[\"image\"],\n",
    "                dtype=torch.float32,\n",
    "                affine=None,\n",
    "                invert_affine=True,\n",
    "            ),\n",
    "        ],\n",
    "        map_items=True,\n",
    "        log_stats=True,\n",
    "        lazy=LAZY,\n",
    "        overrides={'image': {'padding_mode': 'zeros'}},\n",
    "    )\n",
    "    if seed:\n",
    "        transform.set_random_state(seed=seed)\n",
    "\n",
    "    for run_name, ori_tomo, ori_kpts in zip(RUNS, all_tomos, all_kpts):\n",
    "        kpts = ori_kpts\n",
    "        print('BEFORE:', f'shape={ori_tomo.shape} dtype={ori_tomo.dtype} min={ori_tomo.min()} mean={ori_tomo.mean()} std={ori_tomo.std()} max={ori_tomo.max()}')\n",
    "        data = {\n",
    "            'image': np.transpose(ori_tomo, (2, 1, 0))[None], # ZYX --> 1XYZ\n",
    "            'kpts': kpts[None],\n",
    "        }\n",
    "        data = transform(data)\n",
    "        image = np.transpose(data[\"image\"][0], (2,1,0)) # 1XYZ -> ZYX\n",
    "        \n",
    "        print('AFTER:', f'shape={image.shape} dtype={image.dtype} min={image.min()} mean={image.mean()} std={image.std()} max={image.max()}')\n",
    "        kpts = data[\"kpts\"]\n",
    "        assert kpts.shape[0] == 1\n",
    "        # zy, zx, yx <-> 6,7,8\n",
    "        # xy, xz, yz <-> 8, 7, 6\n",
    "        kpts = kpts[0, :, [2,1,0,5,4,3,8,7,6,9]]\n",
    "        # kpts = torch.cat([_kpts[0][:, [2,1,0]], kpts[:, 3:]], dim=-1)\n",
    "        # filter invalid keypoints\n",
    "        image_shape = image.shape\n",
    "        kpts = crop_kpts(kpts, [0, 0, 0], image_shape)\n",
    "        assert kpts.shape[1] == 10\n",
    "\n",
    "        # if view_3d, use itkwidgets\n",
    "        if view_3d:\n",
    "            image = (np.clip(image, a_min=0, a_max=1.0) * 255).astype(np.uint8)\n",
    "            view(image = image, point_set = kpts[:, [2, 1, 0]])\n",
    "            return\n",
    "        \n",
    "\n",
    "        K=4\n",
    "        kpt_zyxs = np.round((kpts[:, :3] - 0.5).numpy())\n",
    "        topk_freq = select_top_k_unique_keypoints(kpt_zyxs, K=K)\n",
    "        if len(topk_freq) < K:\n",
    "            print(f'Sample top {len(topk_freq)}/{K}')\n",
    "            for _ in range(K - len(topk_freq)):\n",
    "                topk_freq.append([random.randrange(0, axis_shape) for axis_shape in image.shape])\n",
    "        topk_freq.sort(key = lambda x: x[0])\n",
    "        topk_freq = np.array(topk_freq, dtype = int)\n",
    "        \n",
    "        print('RUN:', run_name)\n",
    "        for axis in ['z', 'y', 'x']:\n",
    "            axis_idx = {'z': 0, 'y': 1, 'x': 2}[axis]\n",
    "            # tomo, slice_idxs = select(image, 4, axis)\n",
    "\n",
    "            slice_idxs = topk_freq[:, axis_idx]\n",
    "            _slices = [slice(None), slice(None), slice(None)]\n",
    "            _slices[axis_idx] = slice_idxs\n",
    "            tomo = image[*_slices]\n",
    "            permute = [0, 1, 2]\n",
    "            permute.remove(axis_idx)\n",
    "            new_permute = [axis_idx, *permute]\n",
    "            tomo = np.transpose(tomo, new_permute)\n",
    "            \n",
    "            print(f'axis={axis} axis_idx={axis_idx} slices={slice_idxs} tomo_shape={tomo.shape}')\n",
    "            # tomo = (((tomo - tomo.min()) / (tomo.max() - tomo.min())) * 255).astype(np.uint8)\n",
    "            \n",
    "            # draw kpts as circles\n",
    "            viz_tomo_slices = []\n",
    "            for j, (slice_idx, tomo_slice) in enumerate(zip(slice_idxs, tomo)):\n",
    "                \n",
    "                tomo_slice = (np.clip(tomo_slice, a_min=0, a_max=1.0) * 255).astype(np.uint8)\n",
    "                tomo_slice = np.repeat(tomo_slice[..., None], 3, axis = -1) # HW -> HW3\n",
    "\n",
    "                # draw 2 projection lines\n",
    "                _tmp = [0, 1, 2]\n",
    "                _tmp.remove(axis_idx)\n",
    "                proj_row_idx = topk_freq[j, _tmp[0]]\n",
    "                proj_col_idx = topk_freq[j, _tmp[1]]\n",
    "                H, W = tomo_slice.shape[:2]\n",
    "                cv2.line(tomo_slice, (0, proj_row_idx), (W-1, proj_row_idx), AXIS_COLORS[_tmp[0]], thickness=1) \n",
    "                cv2.line(tomo_slice, (proj_col_idx, 0), (proj_col_idx, H-1), AXIS_COLORS[_tmp[1]], thickness=1) \n",
    "                \n",
    "                _squared_radius = kpts[:, axis_idx + 3] ** 2 -  (kpts[:, axis_idx] - slice_idx - 0.5) ** 2\n",
    "                # keep = _squared_radius > 0\n",
    "\n",
    "                # +-2 slices\n",
    "                # _dist_thres = (kpts[:, axis_idx + 3] / 3)\n",
    "                _dist_thres = 2.0\n",
    "                keep = torch.abs(kpts[:, axis_idx] - slice_idx - 0.5) <= _dist_thres\n",
    "\n",
    "                keep_kpts = kpts[keep]\n",
    "                keep_radius = _squared_radius[keep] ** 0.5\n",
    "                assert len(keep_kpts) == len(keep_radius)\n",
    "\n",
    "                # for _kpt in keep_kpts:\n",
    "                #     _sigma = PARTICLE_SIGMAS[list(PARTICLE_SIGMAS.keys())[int(_kpt[-1])]] * 3\n",
    "                #     print(f'class={_kpt[-1]} sigma={_sigma} sigma_ZYX={_kpt[3], _kpt[4], _kpt[5]}')\n",
    "                \n",
    "                # print(f'slice {slice_idx} keep {len(keep_kpts)} keypoints')\n",
    "                \n",
    "                for kpt, radius in zip(keep_kpts, keep_radius.tolist()):\n",
    "                    cov33 = kpt[[3, 6, 7, 6, 4, 8, 7, 8, 5]].reshape(3,3)\n",
    "                    h_axis, w_axis = _tmp\n",
    "                    mean = [kpt[w_axis], kpt[h_axis]]\n",
    "                    cov = np.array([[cov33[w_axis, w_axis], cov33[w_axis, h_axis]],\n",
    "                                    [cov33[w_axis, h_axis], cov33[h_axis, h_axis]]\n",
    "                                   ])                    \n",
    "                    # Draw the ellipse on the image\n",
    "                    # cv2.ellipse(tomo_slice, coord,  (round(kpt[3 + w_axis].item()), round(kpt[3 + h_axis].item())), 0, 0, 360, COLORS[int(kpt[-1])], thickness=2)\n",
    "                    draw_ellipse_from_normal_distribution(tomo_slice, mean, cov, color=COLORS[int(kpt[-1])], thickness=2)\n",
    "                    \n",
    "                viz_tomo_slices.append(tomo_slice)\n",
    "                    \n",
    "            row = concat_imgs(viz_tomo_slices, max_h = None, max_w = None, axis = 1, border_width = 5)\n",
    "            display_img(row, max_h = None, max_w = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6c90e1-f0c1-4dca-b0bc-e043ef2522c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "[e + 3 for e in [0, 3, 4, 3, 1, 5, 4, 5, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cb1d28-ad76-458e-af77-e6e6ba91b1fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c076dd3-a2dc-4e54-9347-6daa783b5edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUNS = ['TS_5_4', 'TS_69_2', 'TS_6_4', 'TS_6_6', 'TS_73_6', 'TS_86_3', 'TS_99_9']\n",
    "PARTICLE_RADIUS = {\n",
    "    k: v / 10 for k, v in _PARTICLE_RADIUS.items()\n",
    "}\n",
    "print('RADIUS:', PARTICLE_RADIUS)\n",
    "PARTICLE_SIGMAS = {k: v * 1 for k, v in PARTICLE_RADIUS.items()}\n",
    "print('SIGMA:', PARTICLE_SIGMAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190a29cf-af5a-44d2-af46-ad800bf9a76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.scan_csv('/home/dangnh36/datasets/czii/processed/gt_6.csv').with_columns(\n",
    "    pl.col('x') / SCALE_X,\n",
    "    pl.col('y') / SCALE_Y,\n",
    "    pl.col('z') / SCALE_Z\n",
    ").collect()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e74edd-934a-4561-b1ac-4c70c7ff2eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_kpts = []\n",
    "for run_name in RUNS:\n",
    "    run_kpts = []\n",
    "    for particle_idx, (particle_type, particle_sigma) in enumerate(\n",
    "            PARTICLE_SIGMAS.items()\n",
    "        ):\n",
    "        sub_df = df.filter((pl.col('particle_type') == particle_type) & (pl.col('experiment') == run_name))\n",
    "        for row in sub_df.iter_rows(named = True):\n",
    "            # x, y, z, cls\n",
    "            run_kpts.append(\n",
    "                [\n",
    "                    row['x'],\n",
    "                    row['y'],\n",
    "                    row['z'],\n",
    "                    (particle_sigma * 1) ** 2,  # cov_xx\n",
    "                    (particle_sigma * 1) ** 2,  # cov_yy\n",
    "                    (particle_sigma * 1) ** 2,  # cov_zz\n",
    "                    0, # cov_xy\n",
    "                    0, # cov_xz\n",
    "                    0, # cov_yz\n",
    "                    particle_idx,\n",
    "                ]\n",
    "            )\n",
    "    run_kpts = torch.tensor(run_kpts, dtype=torch.float32)\n",
    "    all_kpts.append(run_kpts)\n",
    "print(len(all_kpts))\n",
    "print([e.shape for e in all_kpts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b211c355-2934-4f8a-9b05-c9315e14710e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_kpts[0][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0422b7-ccd7-4c9e-9e15-78574ed82b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOMO_TYPE = 'denoised'\n",
    "SCALE = 0\n",
    "\n",
    "all_tomos = []\n",
    "for run_name in tqdm(RUNS):\n",
    "    npy_path = f'/home/dangnh36/datasets/czii/processed/npy_dataset/{TOMO_TYPE}/{SCALE}/{run_name}.npy'\n",
    "    tomo = np.load(npy_path)\n",
    "    all_tomos.append(tomo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ef7316-8059-47d4-a878-c91e4c76ebe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944d3d43-36c2-4338-b858-6f778f416f73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c63571e-25c8-4735-8b26-2c6b34fdbf76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92d9b845-d765-4bdf-9282-20cad68b78bc",
   "metadata": {},
   "source": [
    "## Test Invertd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2e8fb6-4704-44ec-87b5-84b9f896cdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'image': torch.from_numpy(all_tomos[2]).permute(2,1,0)[None],\n",
    "    'kpts': all_kpts[2][None]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676deb29-812d-4c20-bf9c-13b25411fa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import pi\n",
    "\n",
    "pre_transform = T.Compose([\n",
    "    T.RandSpatialCropd(keys=[\"image\"], roi_size=[320, 240, 64], random_center=True, random_size=False, lazy=True),\n",
    "    T.RandAffined(keys = ['image'], prob=1.0,\n",
    "                  rotate_range=((0,0), (0.0), (0, 0)), shear_range=None, \n",
    "                  translate_range=((0,0), (0,0), (0, 0)),\n",
    "                  scale_range=((-0.0, 0.0),(-0.0, 0.0),(-0.0, 0.0)),\n",
    "                  spatial_size=None, mode='bilinear', padding_mode='constant', \n",
    "                  cache_grid=True, device=None, lazy=True),\n",
    "    T.RandZoomd(keys=['image'], prob=1.0, min_zoom=(2.0, 1), max_zoom=(2.0, 1), mode='bilinear',\n",
    "             padding_mode='constant', align_corners=False, keep_size=True, lazy=True),\n",
    "    T.ScaleIntensityRangePercentilesd(\n",
    "                keys=[\"image\"],\n",
    "                lower=5,\n",
    "                upper=95,\n",
    "                b_min=0.0,\n",
    "                b_max=1.0,\n",
    "                clip=True,\n",
    "                relative=False,\n",
    "                channel_wise=False,\n",
    "            )\n",
    "])\n",
    "\n",
    "inv_transform = T.Invertd(\n",
    "    keys=[\"image\"],  # invert the `pred` data field, also support multiple fields\n",
    "    transform=pre_transform,\n",
    "    orig_keys=['image'],  # get the previously applied pre_transforms information on the `img` data field,\n",
    "    # then invert `pred` based on this information. we can use same info\n",
    "    # for multiple fields, also support different orig_keys for different fields\n",
    "    nearest_interp=False,  # don't change the interpolation mode to \"nearest\" when inverting transforms\n",
    "    # to ensure a smooth output, then execute `AsDiscreted` transform\n",
    "    to_tensor=True,  # convert to PyTorch Tensor after inverting\n",
    ")\n",
    "print(pre_transform, inv_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b20575-906c-4cd2-965a-82d58af61ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = pre_transform(data)\n",
    "print(ret.keys())\n",
    "print(ret['image'].shape, ret['image'].dtype)\n",
    "inv_ret = inv_transform(ret)\n",
    "print(inv_ret.keys())\n",
    "print(inv_ret['image'].shape, inv_ret['image'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6ffc89-4091-4efd-9bb0-39f358dd8ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = inv_ret['image'][0].cpu().numpy()\n",
    "print(image.min(), image.max(), image.shape)\n",
    "image = (np.clip(image, a_min=0, a_max=1.0) * 255).astype(np.uint8)\n",
    "view(image = image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bab30ed-ad29-499e-82c7-8461d06a8778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b2a83e-d1d0-47ac-9ee4-31e57543f605",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78479f49-d6e0-4018-91df-fdbde1216a3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c78166-e212-4974-9dd2-2ee9c73c2b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from math import pi\n",
    "\n",
    "LOG_STATS = False\n",
    "OVERRIDES = {'image': {'padding_mode': 'zeros'}}\n",
    "MAX_XY_ROTATE = pi/6\n",
    "ALIGN_CORNERS = False\n",
    "\n",
    "\n",
    "# Rotate\n",
    "T.OneOf(\n",
    "    transforms=[\n",
    "        T.RandRotated(keys = ['image'], range_x=(-pi/6, pi/6), range_y=(-pi/6, pi/6), range_z=(0, 2*pi), prob=1.0, keep_size=True, mode='bilinear', padding_mode='zeros', align_corners=ALIGN_CORNERS, lazy=LAZY),\n",
    "    ],\n",
    "    weights=None,\n",
    "    log_stats=LOG_STATS,\n",
    "    lazy=LAZY,\n",
    "    overrides=OVERRIDES\n",
    ")\n",
    "\n",
    "# Flip\n",
    "T.RandFlipd(keys = ['image'], prob=0.5, spatial_axis=0, lazy=LAZY),\n",
    "T.RandFlipd(keys = ['image'], prob=0.5, spatial_axis=1, lazy=LAZY),\n",
    "T.RandFlipd(keys = ['image'], prob=0.5, spatial_axis=2, lazy=LAZY),\n",
    "# T.Rotate180()\n",
    "\n",
    "\n",
    "\n",
    "# Affine + RandZoom\n",
    "T.RandAffined(keys = ['image'],\n",
    "                  prob=1.0,\n",
    "                  rotate_range=((-pi/6, pi/6), (-pi/6, pi/6), (0, 2*pi)),\n",
    "                  shear_range=((-0.2, 0.2), (-0.2, 0.2), (-0.2, 0.2)),\n",
    "                  translate_range=((0,0), (0,0), (0, 0)),\n",
    "                  scale_range=((-0.3, 0.3), (-0.3, 0.3), (-0.3, 0.3)), # max_skew_xy = 1.3 / 0.7 = 1.86\n",
    "                  spatial_size=None,\n",
    "                  mode='bilinear', # bilinear, nearest\n",
    "                  padding_mode='constant',\n",
    "                  cache_grid=True,\n",
    "                  device=None,\n",
    "                  lazy=LAZY)\n",
    "T.RandZoomd(keys=['image'], prob=1.0, min_zoom=(0.25, 2.0), max_zoom=(0.25, 2.0), mode='bilinear',\n",
    "             padding_mode='constant', align_corners=ALIGN_CORNERS, keep_size=False, lazy=LAZY)\n",
    "\n",
    "# not lazy\n",
    "T.RandGridDistortiond(keys=['image'], num_cells=(10,10,2), prob=1.0, distort_limit=(-0.1, 0.1), mode='bilinear', padding_mode='constant', device=None)\n",
    "T.Rand3DElasticd(keys = ['image'], sigma_range = (11, 11),\n",
    "                     magnitude_range = (5, 5),\n",
    "                     prob=1.0,\n",
    "                     spatial_size=None,\n",
    "                     mode='bilinear',\n",
    "                     padding_mode='constant'\n",
    ")\n",
    "# must include\n",
    "T.RandSimulateLowResolutiond(keys=['image'], prob=1.0, downsample_mode='nearest', upsample_mode='trilinear', zoom_range=(0.3, 0.3), align_corners=ALIGN_CORNERS)\n",
    "\n",
    "# exponent noise\n",
    "# note: (0.5, 1.0) is half of (1.0, 2.0) ==> pixel intensities tend to be darker\n",
    "T.RandSmoothFieldAdjustContrastd(keys = ['image'],\n",
    "                                 spatial_size = (320, 320, 64),\n",
    "                                 rand_size = (80, 80, 16), pad=0, mode='area',\n",
    "                                 align_corners=None, prob=1.0, gamma=(0.5, 2.0)\n",
    "                                )\n",
    "# multiplicative noise\n",
    "T.RandSmoothFieldAdjustIntensityd(\n",
    "        keys = ['image'],\n",
    "        spatial_size = (320, 320, 64),\n",
    "        rand_size = (80, 80, 16),\n",
    "        pad=0, mode='area', align_corners=None, prob=1.0,\n",
    "        gamma=(1.5, 1.51) # 0.5, 1.5\n",
    "    )\n",
    "T.RandSmoothDeformd(keys = ['image'], spatial_size = (320, 320, 64),\n",
    "                       rand_size = (80, 80, 16), pad=0, field_mode='area', align_corners=None,\n",
    "                       prob=1.0, def_range=(-0.02, 0.02), grid_mode='nearest', \n",
    "                       grid_padding_mode='zeros', grid_align_corners=ALIGN_CORNERS\n",
    "                      )\n",
    "\n",
    "T.Transposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3adb67-d056-409d-a7b4-cf2d6936f582",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e2d7d3-4808-4f5f-bcf8-8ee2388f80d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d3216d-5d72-4cfa-a4cc-97041298d9c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949a7c4a-0f0a-4fee-979f-934da8334d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = [\n",
    "    T.RandSpatialCropd(\n",
    "        keys=[\"image\"],\n",
    "        roi_size=[320, 320, 64],\n",
    "        # max_roi_size=(192, 192, 192),\n",
    "        random_center=True,\n",
    "        random_size=False,\n",
    "        lazy=LAZY,\n",
    "    ),\n",
    "    T.RandRotated(keys = ['image'], range_x=(-pi/6, pi/6), range_y=(-pi/6, pi/6), range_z=(0, 2*pi), prob=1.0, keep_size=True, mode='bilinear', padding_mode='zeros', align_corners=ALIGN_CORNERS, lazy=LAZY),\n",
    "]\n",
    "\n",
    "LAZY = True\n",
    "viz_transform(all_tomos, all_kpts, transforms, seed = None, view_3d = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e70cdeb-63a2-4fff-ad0a-31531598d98d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf14017-e316-4f6d-9289-1b99230b48f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = [\n",
    "    T.RandSpatialCropd(\n",
    "        keys=[\"image\"],\n",
    "        roi_size=[320, 320, 64],\n",
    "        # max_roi_size=(192, 192, 192),\n",
    "        random_center=True,\n",
    "        random_size=False,\n",
    "        lazy=LAZY,\n",
    "    ),\n",
    "    T.RandFlipd(keys = ['image'], prob=1.0, spatial_axis=0, lazy=LAZY),\n",
    "    T.RandFlipd(keys = ['image'], prob=1.0, spatial_axis=1, lazy=LAZY),\n",
    "    T.RandFlipd(keys = ['image'], prob=1.0, spatial_axis=2, lazy=LAZY),\n",
    "]\n",
    "\n",
    "LAZY = True\n",
    "viz_transform(all_tomos, all_kpts, transforms, seed = None, view_3d = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d583883-996e-478a-8e01-868f9dbb96df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1d0d7d-2a4a-45e7-bc84-2f82f53bdd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = [\n",
    "    T.RandSpatialCropd(\n",
    "        keys=[\"image\"],\n",
    "        roi_size=[320, 320, 64],\n",
    "        # max_roi_size=(192, 192, 192),\n",
    "        random_center=True,\n",
    "        random_size=False,\n",
    "        lazy=LAZY,\n",
    "    ),\n",
    "    T.RandZoomd(keys=['image'], prob=1.0, min_zoom=(0.25, 2.0), max_zoom=(0.25, 2.0), mode='bilinear',\n",
    "             padding_mode='constant', align_corners=ALIGN_CORNERS, keep_size=False, lazy=LAZY),\n",
    "]\n",
    "\n",
    "LAZY = True\n",
    "viz_transform(all_tomos, all_kpts, transforms, seed = None, view_3d = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3c732c-e824-462e-af7f-908650563351",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab26ca54-8152-4c97-a4e2-c4b01a284cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = [\n",
    "    T.RandSpatialCropd(\n",
    "        keys=[\"image\"],\n",
    "        roi_size=[320, 200, 64],\n",
    "        # max_roi_size=(192, 192, 192),\n",
    "        random_center=True,\n",
    "        random_size=False,\n",
    "        lazy=LAZY,\n",
    "    ),\n",
    "    T.RandAffined(keys = ['image'],\n",
    "                  prob=1.0,\n",
    "                  rotate_range=None,\n",
    "                  shear_range=((0.2, 0.2), (0.2, 0.2), (0.2, 0.2)), # HWD -> parallel to W, D, H\n",
    "                  translate_range=None,\n",
    "                  scale_range=None,\n",
    "                  spatial_size=None,\n",
    "                  mode='bilinear', # bilinear, nearest\n",
    "                  padding_mode='constant',\n",
    "                  cache_grid=True,\n",
    "                  device=None,\n",
    "                  lazy=LAZY)\n",
    "]\n",
    "\n",
    "LAZY = False\n",
    "viz_transform(all_tomos, all_kpts, transforms, seed = None, view_3d = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e3fe5d-34bf-433b-b711-7be03f01562d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cdec68-8126-42f1-b978-04faec4a2f48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b17be4-eb29-487f-82db-bcd068527d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "320 / 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8e5790-e3ec-4ad7-8543-a17795160fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = [\n",
    "    T.RandSpatialCropd(\n",
    "        keys=[\"image\"],\n",
    "        roi_size=[320, 320, 64],\n",
    "        # max_roi_size=(192, 192, 192),\n",
    "        random_center=True,\n",
    "        random_size=False,\n",
    "        lazy=LAZY,\n",
    "    ),\n",
    "    T.RandGridDistortiond(keys=['image'], num_cells=(10,10,2), prob=1.0, distort_limit=(-0.15, 0.15), mode='bilinear', padding_mode='constant', device=None)\n",
    "]\n",
    "\n",
    "LAZY = False\n",
    "viz_transform(all_tomos, all_kpts, transforms, seed = None, view_3d = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380bc2d9-487a-4584-9109-bd2f270f51ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc019476-38d2-417c-a00a-7a3f3115d49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = [\n",
    "    T.RandSpatialCropd(\n",
    "        keys=[\"image\"],\n",
    "        roi_size=[320, 320, 64],\n",
    "        # max_roi_size=(192, 192, 192),\n",
    "        random_center=True,\n",
    "        random_size=False,\n",
    "        lazy=LAZY,\n",
    "    ),\n",
    "    T.Rand3DElasticd(keys = ['image'], sigma_range = (11, 11),\n",
    "                     magnitude_range = (25, 25),\n",
    "                     prob=1.0,\n",
    "                     spatial_size=None,\n",
    "                     mode='bilinear',\n",
    "                     padding_mode='constant'\n",
    "    ),\n",
    "]\n",
    "\n",
    "LAZY = False\n",
    "viz_transform(all_tomos, all_kpts, transforms, seed = None, view_3d = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056a4f82-b8fe-4004-8141-929e66bb8f79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bafd62b-a1d9-499f-ac88-9abbdea2111b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = [\n",
    "    T.RandSpatialCropd(\n",
    "        keys=[\"image\"],\n",
    "        roi_size=[320, 320, 64],\n",
    "        # max_roi_size=(192, 192, 192),\n",
    "        random_center=True,\n",
    "        random_size=False,\n",
    "        lazy=LAZY,\n",
    "    ),\n",
    "    T.RandSimulateLowResolutiond(keys=['image'], prob=1.0, downsample_mode='nearest', upsample_mode='trilinear', zoom_range=(0.3, 0.3), align_corners=ALIGN_CORNERS)\n",
    "]\n",
    "\n",
    "LAZY = True\n",
    "viz_transform(all_tomos, all_kpts, transforms, seed = None, view_3d = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c968aaeb-3e67-4bad-a570-9780f5618bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5028c1-3d46-4150-8749-f310d73d3863",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = [\n",
    "    T.RandSpatialCropd(\n",
    "        keys=[\"image\"],\n",
    "        roi_size=[320, 320, 64],\n",
    "        # max_roi_size=(192, 192, 192),\n",
    "        random_center=True,\n",
    "        random_size=False,\n",
    "        lazy=LAZY,\n",
    "    ),\n",
    "    T.RandSmoothFieldAdjustContrastd(keys = ['image'],\n",
    "                                     spatial_size = (320, 320, 64),\n",
    "                                     rand_size = (80, 80, 16), pad=0, mode='area',\n",
    "                                     align_corners=None, prob=1.0, gamma=(0.5, 2.0)),\n",
    "]\n",
    "\n",
    "LAZY = True\n",
    "viz_transform(all_tomos, all_kpts, transforms, seed = None, view_3d = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc60e8c-9abe-447e-9c3d-8ccee8c34f21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc2fb63-4666-475b-8a71-336879f547eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = [\n",
    "    T.RandSpatialCropd(\n",
    "        keys=[\"image\"],\n",
    "        roi_size=[320, 320, 64],\n",
    "        # max_roi_size=(192, 192, 192),\n",
    "        random_center=True,\n",
    "        random_size=False,\n",
    "        lazy=LAZY,\n",
    "    ), \n",
    "    T.RandSmoothFieldAdjustIntensityd(\n",
    "        keys = ['image'],\n",
    "        spatial_size = (320, 320, 64),\n",
    "        rand_size = (80, 80, 16),\n",
    "        pad=0, mode='area', align_corners=None, prob=1.0,\n",
    "        gamma=(1.5, 1.51) # 0.5, 1.5\n",
    "    )\n",
    "]\n",
    "\n",
    "LAZY = True\n",
    "viz_transform(all_tomos, all_kpts, transforms, seed = None, view_3d = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbef2255-d425-4ed2-ae96-bb1043d34c93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fd619f-2b41-4594-8b86-08063ddf1a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "H, W, D = (320, 320, 64)\n",
    "\n",
    "transforms = [\n",
    "    T.RandSpatialCropd(\n",
    "        keys=[\"image\"],\n",
    "        roi_size=[320, 320, 64],\n",
    "        # max_roi_size=(192, 192, 192),\n",
    "        random_center=True,\n",
    "        random_size=False,\n",
    "        lazy=LAZY,\n",
    "    ),\n",
    "    # T.RandSmoothDeformd(keys = ['image'], spatial_size = (320, 320, 64),\n",
    "    #                    rand_size = (80, 80, 16), pad=0, field_mode='area', align_corners=None,\n",
    "    #                    prob=1.0, def_range=(-0.02, 0.02), grid_mode='nearest', \n",
    "    #                    grid_padding_mode='zeros', grid_align_corners=ALIGN_CORNERS\n",
    "    #                   ),\n",
    "\n",
    "    T.RandSmoothDeformd(\n",
    "            keys=['image'],\n",
    "            spatial_size=(H, W, D),\n",
    "            rand_size=(H // 4, W // 4, D // 4),\n",
    "            pad=0,\n",
    "            field_mode=\"area\",\n",
    "            align_corners=None,\n",
    "            prob=1.0,\n",
    "            # 6 is min of particle radius (apo-ferritin)\n",
    "            def_range=(-6.0 / max(H, W, D), 6.0 / max(H, W, D)),\n",
    "            grid_mode=\"nearest\",\n",
    "            grid_padding_mode=\"zeros\",\n",
    "            grid_align_corners=ALIGN_CORNERS,\n",
    "        ),\n",
    "]\n",
    "\n",
    "LAZY = True\n",
    "viz_transform(all_tomos, all_kpts, transforms, seed = None, view_3d = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d440a41-1540-4c56-a84d-9935aecf2a1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073b551f-30bd-4bb8-af3b-08040fb6240c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = [\n",
    "    T.RandSpatialCropd(\n",
    "        keys=[\"image\"],\n",
    "        roi_size=[320, 240, 64],\n",
    "        # max_roi_size=(192, 192, 192),\n",
    "        random_center=True,\n",
    "        random_size=False,\n",
    "        lazy=LAZY,\n",
    "    ),\n",
    "    CT.RandRotate180d(keys=['image'], prob=1.0, spatial_axes=(0, 1), lazy=LAZY),\n",
    "]\n",
    "\n",
    "LAZY = True\n",
    "viz_transform(all_tomos, all_kpts, transforms, seed = 42, view_3d = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb309dc-c6dc-45f9-926f-b09db084325a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6d2333-e61b-49b3-9413-add0fc0df483",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc15d8ed-5f84-4f2f-9fc1-2f7516898df8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47b7d8a2-0aec-4d09-bf0a-143fe95848c1",
   "metadata": {},
   "source": [
    "## Intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ed8874-aa0c-4438-ad92-7375111728c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOCAL NOISE\n",
    "T.RandGaussianNoised(['image'], prob=1.0, mean=0.0, std=0.2, sample_std=True)\n",
    "\n",
    "# GLOBAL INTENSITY CHANGE\n",
    "# mean shift\n",
    "T.RandShiftIntensityd(['image'], offsets = (-0.35, 0.35), safe=False, prob=1.0, channel_wise=True)\n",
    "T.RandStdShiftIntensityd(['image'], (-1.35, 1.35), prob=1.0, nonzero=False, channel_wise=True)\n",
    "# std scale (multiplicative)\n",
    "T.RandScaleIntensityFixedMeand(['image'], prob=1.0, factors=(-0.3, 0.3), fixed_mean=True, preserve_range=False)\n",
    "\n",
    "\n",
    "# mean/std scale (multiplicative)\n",
    "T.RandScaleIntensityd(['image'], factors = (-0.6, 0.4), prob=1.0, channel_wise=True)\n",
    "# mean/std polynomial (x**gamma)\n",
    "T.RandAdjustContrastd(['image'], prob=1.0, gamma=(0.5, 1.5), invert_image=False, retain_stats=False)\n",
    "# histogram modification\n",
    "T.RandHistogramShiftd(['image'], num_control_points=(6,15), prob=1.0)\n",
    "\n",
    "# SMOOTHEN\n",
    "T.MedianSmoothd(['image'], radius = 1) # slow on CPU, radius >=2 -> large RAM\n",
    "T.RandGaussianSmoothd(['image'], sigma_x=(0.5, 1.25), sigma_y=(0.5, 1.25), sigma_z=(0.5, 1.25), prob=1.0, approx='erf')\n",
    "\n",
    "\n",
    "# DROPOUT\n",
    "\n",
    "\n",
    "# WE NEED READ MORE ABOUT THIS\n",
    "T.RandBiasFieldd(['image'], degree=3, coeff_range=(-0.5, -0.5), prob=1.0)\n",
    "T.RandGaussianSharpend(['image'], sigma1_x=(0.5, 1.0), sigma1_y=(0.5, 1.0), sigma1_z=(0.5, 1.0),\n",
    "                      sigma2_x=0.5, sigma2_y=0.5, sigma2_z=0.5,\n",
    "                      alpha=(10.0, 30.0), approx='erf', prob=1.0)\n",
    "T.RandGibbsNoised(['image'], prob=1.0, alpha=(0.0, 0.7))\n",
    "\n",
    "\n",
    "# LAST PREPROCESS STEP\n",
    "T.HistogramNormalized(['image'], num_bins=256, min=0, max=1.0, mask=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68e1289-8e63-444b-9e0a-ca0b23b77527",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.35 / 0.26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64ce13f-c828-4bf9-a8a2-a33eb4509413",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - (1 - 0.8) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a524f1-01b0-4f76-bed1-b5475dd2f42c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220e2741-c13b-412f-9d1a-7e0db3cd98e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transforms = [\n",
    "    T.RandSpatialCropd(keys=[\"image\"], roi_size=[320, 320, 64], random_center=True, random_size=False, lazy=LAZY),    \n",
    "]\n",
    "LAZY = True\n",
    "viz_transform(all_tomos, all_kpts, transforms, seed = 611, view_3d = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b5c825-5b9f-4fdc-a4e2-3dce85a73302",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = [\n",
    "    T.RandSpatialCropd(keys=[\"image\"], roi_size=[320, 320, 64], random_center=True, random_size=False, lazy=LAZY),\n",
    "    T.RandRotate90d(keys=[\"image\"], prob=1.0, max_k=1, spatial_axes=(0, 1), lazy=LAZY),\n",
    "    # T.RandZoomd(keys=['image'], prob=1.0, min_zoom=(0.8, 2.0, 1.0), max_zoom=(0.8, 2.0, 1.0), mode='bilinear',\n",
    "    #          padding_mode='constant', align_corners=ALIGN_CORNERS, keep_size=True, lazy=LAZY),\n",
    "    # # T.RandAffined(keys = ['image'], prob=1.0, rotate_range=((0,0), (0,0), (pi/4, pi/3)), shear_range=None, translate_range=((0,0), (0,0), (0, 0)), \n",
    "    # #               scale_range=((0, 0),(0,0),(0,0)), spatial_size=None, mode='bilinear', padding_mode='constant',\n",
    "    # #               cache_grid=True, device=None, lazy=LAZY)\n",
    "    # T.RandAffined(keys = ['image'], prob=1.0,\n",
    "    #               rotate_range=((0,0), (0,0), (0,2*pi)),\n",
    "    #               shear_range=((0.2, 0.2), (0.2, 0.2), (0.2, 0.2)),\n",
    "    #               translate_range=((0,0), (0,0), (0, 0)), \n",
    "    #               scale_range=((-0.2, 0.2),(-0.2,0.2),(-0.2,0.2)), spatial_size=None, mode='bilinear', padding_mode='constant',\n",
    "    #               cache_grid=True, device=None, lazy=LAZY)\n",
    "]\n",
    "LAZY = True\n",
    "viz_transform(all_tomos, all_kpts, transforms, seed = 611, view_3d = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dba078b-17ad-41e1-a534-ae3a609a61a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6a7cf7-448e-459f-acb4-6c0b74c74c63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e81ad79-57c1-49fa-9601-723bd87030eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a2c513-fdc0-4252-85bf-f0afea4696db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86d6522-0d4c-4a1a-9153-449b5c872b33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
